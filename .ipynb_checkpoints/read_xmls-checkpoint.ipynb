{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(dc):\n",
    "    if type(dc) == list:\n",
    "        result = [\n",
    "            unidecode(i.get(\"#text\").title().strip())\n",
    "            for i in dc\n",
    "            if i.get(\"#text\") is not None and i.get(\"@scheme\") != \"institution\"\n",
    "        ]\n",
    "        return [x for x in result if x != \"And Others\"]\n",
    "    elif dc.get(\"#text\") is not None and dc.get(\"@scheme\") != \"institution\":\n",
    "        return [unidecode(dc.get(\"#text\").title().strip())]\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    if ', ' in name:\n",
    "        lst = name.split(', ')\n",
    "        lst = [item.split(' ')[0] for item in lst]\n",
    "        return lst[1] + ' ' + lst[0]\n",
    "    elif ',' in name:\n",
    "        lst = name.split(',')\n",
    "        lst = [item.split(' ')[0] for item in lst]\n",
    "        return lst[1] + ' ' + lst[0]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_edges(auth_list):\n",
    "    return list(combinations(auth_list, 2))\n",
    "\n",
    "def extract_ids(dc):\n",
    "    if type(dc) == list:\n",
    "        return [\n",
    "            i.get(\"#text\").upper().strip()\n",
    "            for i in dc\n",
    "            if i.get(\"#text\") is not None and i.get(\"@scheme\") == \"eric_accno\"\n",
    "        ][0]\n",
    "    elif dc.get(\"#text\") is not None and dc.get(\"@scheme\") == \"eric_accno\":\n",
    "        return dc.get(\"#text\").upper().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [11:07<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 908421 entries, 17594 to 44897\n",
      "Data columns (total 39 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   dcterms:accessRights       908421 non-null  object\n",
      " 1   dc:subject                 908417 non-null  object\n",
      " 2   dc:creator                 908421 non-null  object\n",
      " 3   dc:type                    908421 non-null  object\n",
      " 4   eric:keywords              398883 non-null  object\n",
      " 5   eric:keywords_geo          301814 non-null  object\n",
      " 6   eric:issn                  746293 non-null  object\n",
      " 7   dc:language                905402 non-null  object\n",
      " 8   dcterms:educationLevel     326980 non-null  object\n",
      " 9   dc:description             907932 non-null  object\n",
      " 10  dc:identifier              908421 non-null  object\n",
      " 11  dc:title                   908421 non-null  object\n",
      " 12  dc:source                  908421 non-null  object\n",
      " 13  eric:citation              908376 non-null  object\n",
      " 14  dc:date                    908417 non-null  object\n",
      " 15  eric:sponsor               14917 non-null   object\n",
      " 16  eric:isbn                  86 non-null      object\n",
      " 17  dcterms:audience           70910 non-null   object\n",
      " 18  eric:pageCount             529933 non-null  object\n",
      " 19  dc:publisher               534037 non-null  object\n",
      " 20  eric:peer_reviewed         908421 non-null  object\n",
      " 21  eric:dateAdded             908421 non-null  object\n",
      " 22  eric:referenceCount        635428 non-null  object\n",
      " 23  eric:abstractor            530523 non-null  object\n",
      " 24  eric:issue                 687778 non-null  object\n",
      " 25  eric:ies_funded            4275 non-null    object\n",
      " 26  eric:contract_number       15005 non-null   object\n",
      " 27  eric:wwcguide_link         916 non-null     object\n",
      " 28  eric:ies_publication_link  2 non-null       object\n",
      " 29  eric:ies_datasource_link   172 non-null     object\n",
      " 30  eric:note                  17499 non-null   object\n",
      " 31  eric:keywords_test         30575 non-null   object\n",
      " 32  eric:keywords_law          11050 non-null   object\n",
      " 33  type                       908421 non-null  object\n",
      " 34  eric:ies_cited             2424 non-null    object\n",
      " 35  eric:wwc_reviewed          928 non-null     object\n",
      " 36  authors                    908421 non-null  object\n",
      " 37  edges                      908421 non-null  object\n",
      " 38  ids                        908421 non-null  object\n",
      "dtypes: object(39)\n",
      "memory usage: 277.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all = []\n",
    "\n",
    "for year in tqdm(range(1965, 2021)):\n",
    "    file_name = \"data/eric\" + str(year)\n",
    "    with open(file_name + \".xml\", encoding=\"utf-8\") as fd:\n",
    "        dict = xmltodict.parse(fd.read())\n",
    "    recs = [rec[\"metadata\"] for rec in dict[\"records\"][\"record\"]]\n",
    "    df = pd.DataFrame(recs)\n",
    "    df = df[df['dc:type'].notna()]\n",
    "    df = df[df['eric:peer_reviewed'].notna()]\n",
    "    df['type'] = [''.join(map(str, l)).lower() for l in df['dc:type']]\n",
    "    df = df.loc[df['eric:peer_reviewed'] == 'T']\n",
    "    # df = df[['ids', 'authors', 'edges', 'dc:type', 'dc:subject', 'eric:keywords', 'eric:keywords_geo', 'dc:title', 'eric:pageCount', 'dc:date', 'eric:dateAdded']]\n",
    "    df_all.append(df)\n",
    "df_all = pd.concat(df_all)\n",
    "\n",
    "df_all = df_all.loc[(df_all['type'].str.contains(\"journal\"))]\n",
    "df_all[\"authors\"] = df_all.apply(lambda row: extract_authors(row[\"dc:creator\"]), axis=1)\n",
    "df_all = df_all[df_all['authors'].notna()]\n",
    "df_all['authors'] = df_all.apply(lambda row: [clean_name(item) for item in row['authors']], axis=1)\n",
    "df_all[\"edges\"] = df_all.apply(lambda row: get_edges(sorted(row[\"authors\"])), axis=1)\n",
    "df_all[\"ids\"] = df_all.apply(lambda row: extract_ids(row[\"dc:identifier\"]), axis=1)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009    41251\n",
       "2016    38588\n",
       "2017    38305\n",
       "2014    37226\n",
       "2020    37152\n",
       "2010    37039\n",
       "2019    36992\n",
       "2015    36610\n",
       "2011    36226\n",
       "2018    35528\n",
       "2008    35104\n",
       "2012    35059\n",
       "2007    28125\n",
       "2013    19696\n",
       "2006    18837\n",
       "2005    18775\n",
       "2002    18486\n",
       "2000    17873\n",
       "2003    17449\n",
       "1999    17212\n",
       "1994    16970\n",
       "1995    16748\n",
       "1996    16117\n",
       "1997    15988\n",
       "2001    15853\n",
       "1981    15090\n",
       "1980    15008\n",
       "1992    14889\n",
       "1989    14852\n",
       "1993    14683\n",
       "1998    14482\n",
       "1991    14467\n",
       "1990    14224\n",
       "1984    13707\n",
       "1983    13565\n",
       "1987    13475\n",
       "1985    13415\n",
       "1986    13360\n",
       "1988    12683\n",
       "1982    12408\n",
       "1979     7996\n",
       "2004     6432\n",
       "1975      131\n",
       "1976       96\n",
       "1977       81\n",
       "1972       42\n",
       "1973       36\n",
       "1974       34\n",
       "1971       28\n",
       "1978       28\n",
       "Name: eric:dateAdded, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['eric:dateAdded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(df_local):\n",
    "\n",
    "    nodelist1 = df_local[\"authors\"].tolist()\n",
    "    nodelist2 = [x for x in nodelist1 if x is not None]  # remove none\n",
    "    node_list = [item for sublist in nodelist2 for item in sublist]\n",
    "    node_list = list(set(node_list))\n",
    "\n",
    "    edge_list1 = df_local[\"edges\"].tolist()\n",
    "    edge_list2 = [x for x in edge_list1 if x is not None]  # remove none\n",
    "    edge_list = [item for sublist in edge_list2 for item in sublist]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_list)\n",
    "    G.add_edges_from(edge_list)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>n_papers</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>n_collabs</th>\n",
       "      <th>n_isolates</th>\n",
       "      <th>mean_collabs</th>\n",
       "      <th>largest_component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1965</td>\n",
       "      <td>908421</td>\n",
       "      <td>697452</td>\n",
       "      <td>1545765</td>\n",
       "      <td>115526</td>\n",
       "      <td>4.432606</td>\n",
       "      <td>0.635176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  n_papers  n_authors  n_collabs  n_isolates  mean_collabs  \\\n",
       "0  1965    908421     697452    1545765      115526      4.432606   \n",
       "\n",
       "   largest_component  \n",
       "0           0.635176  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "\n",
    "for year in tqdm(range(1965, 2021)):\n",
    "    \n",
    "    df_local = df_all.loc[df_all['eric:dateAdded'] == str(year)]\n",
    "    \n",
    "    if len(df_local) == 0:\n",
    "        continue\n",
    "    \n",
    "    G = generate_graph(df_local)\n",
    "    n_papers = len(df_local)\n",
    "    n_authors = len(G)\n",
    "    n_collabs = nx.number_of_edges(G)\n",
    "    n_isolates = nx.number_of_isolates(G)\n",
    "    mean_collabs = 2 * G.number_of_edges() / float(G.number_of_nodes())\n",
    "    \n",
    "    G_largest_comp = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "    largest_component = len(G_largest_comp)/len(G) \n",
    "    \n",
    "    list1.append((year, n_papers, n_authors, n_collabs, n_isolates, mean_collabs, largest_component))\n",
    "\n",
    "df_summary = pd.DataFrame(list1, columns = [\"year\", \"n_papers\", \"n_authors\", \"n_collabs\", \"n_isolates\", \"mean_collabs\", \"largest_component\"])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean papers per author\n",
    "len([item for sublist in list2 for item in sublist])/len(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.degree_histogram(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(G, \"all.edgelist.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.read_edgelist(\"all.edgelist.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_ego = nx.ego_graph(G, \"Prashant Loyalka\")\n",
    "pos = nx.spring_layout(hub_ego)\n",
    "nx.draw(hub_ego, pos, node_color=\"b\", node_size=50, with_labels=False)\n",
    "options = {\"node_size\": 300, \"node_color\": \"r\"}\n",
    "nx.draw_networkx_nodes(hub_ego, pos, nodelist=[\"Prashant Loyalka\"], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([s for s in node_list if \"Steven Raphael\" in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
