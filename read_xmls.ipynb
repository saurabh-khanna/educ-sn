{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import altair as alt\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(dc):\n",
    "    if type(dc) == list:\n",
    "        result = [\n",
    "            unidecode(i.get(\"#text\").title().strip())\n",
    "            for i in dc\n",
    "            if i.get(\"#text\") is not None and i.get(\"@scheme\") != \"institution\"\n",
    "        ]\n",
    "        return [x for x in result if x != \"And Others\"]\n",
    "    elif dc.get(\"#text\") is not None and dc.get(\"@scheme\") != \"institution\":\n",
    "        return [unidecode(dc.get(\"#text\").title().strip())]\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    if ', ' in name:\n",
    "        lst = name.split(', ')\n",
    "        lst = [item.split(' ')[0] for item in lst]\n",
    "        return lst[1] + ' ' + lst[0]\n",
    "    elif ',' in name:\n",
    "        lst = name.split(',')\n",
    "        lst = [item.split(' ')[0] for item in lst]\n",
    "        return lst[1] + ' ' + lst[0]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_edges(auth_list):\n",
    "    return list(combinations(auth_list, 2))\n",
    "\n",
    "def extract_ids(dc):\n",
    "    if type(dc) == list:\n",
    "        return [\n",
    "            i.get(\"#text\").upper().strip()\n",
    "            for i in dc\n",
    "            if i.get(\"#text\") is not None and i.get(\"@scheme\") == \"eric_accno\"\n",
    "        ][0]\n",
    "    elif dc.get(\"#text\") is not None and dc.get(\"@scheme\") == \"eric_accno\":\n",
    "        return dc.get(\"#text\").upper().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [10:41<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 908421 entries, 17594 to 44897\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   dcterms:accessRights       908421 non-null  object\n",
      " 1   dc:subject                 908417 non-null  object\n",
      " 2   dc:creator                 908421 non-null  object\n",
      " 3   dc:type                    908421 non-null  object\n",
      " 4   eric:keywords              398883 non-null  object\n",
      " 5   eric:keywords_geo          301814 non-null  object\n",
      " 6   eric:issn                  746293 non-null  object\n",
      " 7   dc:language                905402 non-null  object\n",
      " 8   dcterms:educationLevel     326980 non-null  object\n",
      " 9   dc:description             907932 non-null  object\n",
      " 10  dc:identifier              908421 non-null  object\n",
      " 11  dc:title                   908421 non-null  object\n",
      " 12  dc:source                  908421 non-null  object\n",
      " 13  eric:citation              908376 non-null  object\n",
      " 14  dc:date                    908417 non-null  object\n",
      " 15  eric:sponsor               14917 non-null   object\n",
      " 16  eric:isbn                  86 non-null      object\n",
      " 17  dcterms:audience           70910 non-null   object\n",
      " 18  eric:pageCount             529933 non-null  object\n",
      " 19  dc:publisher               534037 non-null  object\n",
      " 20  eric:peer_reviewed         908421 non-null  object\n",
      " 21  eric:dateAdded             908421 non-null  object\n",
      " 22  eric:referenceCount        635428 non-null  object\n",
      " 23  eric:abstractor            530523 non-null  object\n",
      " 24  eric:issue                 687778 non-null  object\n",
      " 25  eric:ies_funded            4275 non-null    object\n",
      " 26  eric:contract_number       15005 non-null   object\n",
      " 27  eric:wwcguide_link         916 non-null     object\n",
      " 28  eric:ies_publication_link  2 non-null       object\n",
      " 29  eric:ies_datasource_link   172 non-null     object\n",
      " 30  eric:note                  17499 non-null   object\n",
      " 31  eric:keywords_test         30575 non-null   object\n",
      " 32  eric:keywords_law          11050 non-null   object\n",
      " 33  type                       908421 non-null  object\n",
      " 34  eric:ies_cited             2424 non-null    object\n",
      " 35  eric:wwc_reviewed          928 non-null     object\n",
      " 36  authors                    908421 non-null  object\n",
      " 37  n_authors                  908421 non-null  int64 \n",
      " 38  edges                      908421 non-null  object\n",
      " 39  ids                        908421 non-null  object\n",
      "dtypes: int64(1), object(39)\n",
      "memory usage: 284.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all = []\n",
    "\n",
    "for year in tqdm(range(1965, 2021)):\n",
    "    file_name = \"data/eric\" + str(year)\n",
    "    with open(file_name + \".xml\", encoding=\"utf-8\") as fd:\n",
    "        dict = xmltodict.parse(fd.read())\n",
    "    recs = [rec[\"metadata\"] for rec in dict[\"records\"][\"record\"]]\n",
    "    df = pd.DataFrame(recs)\n",
    "    df = df[df['dc:type'].notna()]\n",
    "    df = df[df['eric:peer_reviewed'].notna()]\n",
    "    df['type'] = [''.join(map(str, l)).lower() for l in df['dc:type']]\n",
    "    df = df.loc[df['eric:peer_reviewed'] == 'T']\n",
    "    # df = df[['ids', 'authors', 'edges', 'dc:type', 'dc:subject', 'eric:keywords', 'eric:keywords_geo', 'dc:title', 'eric:pageCount', 'dc:date', 'eric:dateAdded']]\n",
    "    df_all.append(df)\n",
    "df_all = pd.concat(df_all)\n",
    "\n",
    "df_all = df_all.loc[(df_all['type'].str.contains(\"journal\"))]\n",
    "df_all[\"authors\"] = df_all.apply(lambda row: extract_authors(row[\"dc:creator\"]), axis=1)\n",
    "df_all = df_all[df_all['authors'].notna()]\n",
    "df_all['authors'] = df_all.apply(lambda row: [clean_name(item) for item in row['authors']], axis=1)\n",
    "df_all['n_authors'] = df_all.apply(lambda row: len(row[\"authors\"]), axis=1)\n",
    "df_all[\"edges\"] = df_all.apply(lambda row: get_edges(sorted(row[\"authors\"])), axis=1)\n",
    "df_all[\"ids\"] = df_all.apply(lambda row: extract_ids(row[\"dc:identifier\"]), axis=1)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eric:dateAdded\n",
       "1971    1.000000\n",
       "1972    1.000000\n",
       "1973    1.000000\n",
       "1974    1.000000\n",
       "1975    1.000000\n",
       "1976    1.000000\n",
       "1977    1.000000\n",
       "1978    1.000000\n",
       "1979    1.000000\n",
       "1980    0.999933\n",
       "1981    1.000000\n",
       "1982    1.000000\n",
       "1983    1.000000\n",
       "1984    1.000000\n",
       "1985    1.000000\n",
       "1986    1.000000\n",
       "1987    1.000000\n",
       "1988    1.000000\n",
       "1989    1.000000\n",
       "1990    1.000000\n",
       "1991    1.000000\n",
       "1992    0.999933\n",
       "1993    1.000000\n",
       "1994    0.999529\n",
       "1995    0.999582\n",
       "1996    0.999814\n",
       "1997    1.000000\n",
       "1998    1.000000\n",
       "1999    1.000000\n",
       "2000    0.999944\n",
       "2001    1.000000\n",
       "2002    1.000000\n",
       "2003    0.999885\n",
       "2004    0.998445\n",
       "2005    0.592437\n",
       "2006    0.592186\n",
       "2007    0.481067\n",
       "2008    0.456899\n",
       "2009    0.425032\n",
       "2010    0.389724\n",
       "2011    0.399492\n",
       "2012    0.382241\n",
       "2013    0.383530\n",
       "2014    0.320045\n",
       "2015    0.322835\n",
       "2016    0.318985\n",
       "2017    0.321002\n",
       "2018    0.332780\n",
       "2019    0.324151\n",
       "2020    0.327627\n",
       "Name: dcterms:educationLevel, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby(['eric:dateAdded'])['dcterms:educationLevel'].apply(lambda x: x.isnull().mean())\n",
    "# df_all[\"dc:subject\"].iloc[328615]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anxiety',\n",
       " 'College Students',\n",
       " 'Counselor Client Relationship',\n",
       " 'Depression (Psychology)',\n",
       " 'Males',\n",
       " 'Methods',\n",
       " 'Participation',\n",
       " 'Patients',\n",
       " 'Psychotherapy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_subject(dc):\n",
    "#     if pd.isna(dc):\n",
    "#         return None\n",
    "    result = []\n",
    "    for item in dc:\n",
    "        if type(item) == collections.OrderedDict:\n",
    "            result.append(unidecode(item.get(\"#text\").title().strip()))\n",
    "        elif type(item) == str:\n",
    "            result.append(unidecode(item.title().strip()))\n",
    "        else:\n",
    "            result.append(unidecode(item.title().strip()))\n",
    "    return result\n",
    "\n",
    "extract_subject(df_all[\"dc:subject\"].iloc[17722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 908417/908417 [00:46<00:00, 19395.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df_all = df_all[df_all['dc:subject'].notna()]\n",
    "df_all[\"subjects\"] = df_all.progress_apply(lambda row: extract_subject(row[\"dc:subject\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17594    [Academic Aspiration, Aspiration, Females, Mar...\n",
       "17595    [Adolescents, Aspiration, Career Choice, Child...\n",
       "17596    [Aspiration, Black Attitudes, Black Youth, Mil...\n",
       "17730    [Ability, Career Choice, Career Development, C...\n",
       "17892    [Aspiration, Career Choice, Career Planning, C...\n",
       "                               ...                        \n",
       "44893    [Metacognition, Learning Strategies, College S...\n",
       "44894    [Educational Technology, Technology Uses In Ed...\n",
       "44895    [School Administration, Principals, Leadership...\n",
       "44896    [Mathematics Anxiety, Mathematics Achievement,...\n",
       "44897    [College Athletics, Racial Bias, Gender Bias, ...\n",
       "Name: subjects, Length: 908417, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"subjects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Foreign Countries          55703\n",
       "Academic Achievement       14269\n",
       "Adolescents                12207\n",
       "Higher Education            9843\n",
       "College Students            7813\n",
       "                           ...  \n",
       "Portfolios Assessment          1\n",
       "Rural Environment              1\n",
       "Handwriting Instruction        1\n",
       "Middle Class Standards         1\n",
       "Equal Facilities               1\n",
       "Name: sub1, Length: 5252, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[:, 'sub1'] = df_all.subjects.map(lambda x: x[0])\n",
    "df_all['sub1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6630"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list1 = df_all[\"subjects\"].tolist()\n",
    "node_list2 = [x for x in node_list1 if x is not None]  # remove none\n",
    "node_list3 = [item for sublist in node_list2 for item in sublist]\n",
    "node_list = list(set(node_list3))\n",
    "len(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['eric:dateAdded'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(df_local):\n",
    "\n",
    "    node_list1 = df_local[\"authors\"].tolist()\n",
    "    node_list2 = [x for x in node_list1 if x is not None]  # remove none\n",
    "    node_list3 = [item for sublist in node_list2 for item in sublist]\n",
    "    node_list = list(set(node_list3))\n",
    "\n",
    "    n_papers_per_author = len(node_list3)/len(node_list)\n",
    "    \n",
    "    edge_list1 = df_local[\"edges\"].tolist()\n",
    "    edge_list2 = [x for x in edge_list1 if x is not None]  # remove none\n",
    "    edge_list = [item for sublist in edge_list2 for item in sublist]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_list)\n",
    "    G.add_edges_from(edge_list)\n",
    "    return (G, n_papers_per_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year by year (NOT cumulative)\n",
    "list1 = []\n",
    "\n",
    "for year in tqdm(range(1965, 2021)):\n",
    "    \n",
    "    df_local = df_all.loc[df_all['eric:dateAdded'] == str(year)]\n",
    "    \n",
    "    if len(df_local) == 0:\n",
    "        continue\n",
    "    \n",
    "    result = generate_graph(df_local)\n",
    "    G = result[0]\n",
    "    n_authors = len(G)\n",
    "    n_papers = len(df_local)\n",
    "    \n",
    "    n_authors_per_paper = df_local['n_authors'].mean()\n",
    "    n_papers_per_author = result[1]\n",
    "    \n",
    "    n_collabs = nx.number_of_edges(G)\n",
    "    n_isolates = nx.number_of_isolates(G)\n",
    "    mean_collabs = 2 * G.number_of_edges() / float(G.number_of_nodes())\n",
    "    \n",
    "    G_largest_comp = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "    largest_component = len(G_largest_comp)/len(G) \n",
    "    \n",
    "    deg_assort = nx.degree_assortativity_coefficient(G)\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    transitivity = nx.transitivity(G)\n",
    "    \n",
    "    list1.append((year, n_authors, n_papers, n_authors_per_paper, n_papers_per_author, n_collabs, n_isolates, mean_collabs, largest_component, deg_assort, avg_clustering, transitivity))\n",
    "\n",
    "df_summary = pd.DataFrame(list1, columns = [\"year\", \"n_authors\", \"n_papers\", \"n_authors_per_paper\", \"n_papers_per_author\", \"n_collabs\", \"n_isolates\", \"mean_collabs\", \"largest_component\", \"deg_assort\", \"avg_clustering\", \"transitivity\"])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_authors'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_papers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_authors_per_paper'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_papers_per_author'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_collabs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='mean_collabs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='n_isolates'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='largest_component'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='deg_assort'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='avg_clustering'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\",\n",
    "    interpolate='step-after',\n",
    "    line=True\n",
    ").encode(\n",
    "    x='year',\n",
    "    y='transitivity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "\n",
    "result = generate_graph(df_all)\n",
    "G = result[0]\n",
    "n_authors = len(G)\n",
    "n_papers = len(df_all)\n",
    "\n",
    "n_authors_per_paper = df_all['n_authors'].mean()\n",
    "n_papers_per_author = result[1]\n",
    "\n",
    "n_collabs = nx.number_of_edges(G)\n",
    "n_isolates = nx.number_of_isolates(G)\n",
    "mean_collabs = 2 * G.number_of_edges() / float(G.number_of_nodes())\n",
    "\n",
    "G_largest_comp = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "largest_component = len(G_largest_comp)/len(G) \n",
    "\n",
    "deg_assort = nx.degree_assortativity_coefficient(G)\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "transitivity = nx.transitivity(G)\n",
    "\n",
    "list1.append((year, n_authors, n_papers, n_authors_per_paper, n_papers_per_author, n_collabs, n_isolates, mean_collabs, largest_component, deg_assort, avg_clustering, transitivity))\n",
    "\n",
    "df_overall = pd.DataFrame(list1, columns = [\"year\", \"n_authors\", \"n_papers\", \"n_authors_per_paper\", \"n_papers_per_author\", \"n_collabs\", \"n_isolates\", \"mean_collabs\", \"largest_component\", \"deg_assort\", \"avg_clustering\", \"transitivity\"])\n",
    "df_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "def draw_ego(name):\n",
    "    hub_ego = nx.ego_graph(G, name)\n",
    "    pos = nx.spring_layout(hub_ego)\n",
    "    nx.draw(hub_ego, pos, node_color=\"b\", node_size=50, with_labels=True)\n",
    "    options = {\"node_size\": 300, \"node_color\": \"r\"}\n",
    "    nx.draw_networkx_nodes(hub_ego, pos, nodelist=[name], **options)\n",
    "\n",
    "draw_ego(\"Linda Darling-Hammond\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
