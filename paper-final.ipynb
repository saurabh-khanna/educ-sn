{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "tqdm.pandas()\n",
    "from collections import Counter, OrderedDict\n",
    "import string\n",
    "import json\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(dc):\n",
    "    if type(dc) == list:\n",
    "        result = [\n",
    "            unidecode(i.get(\"#text\").title().strip())\n",
    "            for i in dc\n",
    "            if i.get(\"#text\") is not None and i.get(\"@scheme\") != \"institution\"\n",
    "        ]\n",
    "        return [x for x in result if x != \"And Others\"]\n",
    "    elif dc.get(\"#text\") is not None and dc.get(\"@scheme\") != \"institution\":\n",
    "        return [unidecode(dc.get(\"#text\").title().strip())]\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    if \", \" in name:\n",
    "        lst = name.split(\", \")\n",
    "        lst = [item.split(\" \")[0] for item in lst]\n",
    "        return lst[1] + \" \" + lst[0]\n",
    "    elif \",\" in name:\n",
    "        lst = name.split(\",\")\n",
    "        lst = [item.split(\" \")[0] for item in lst]\n",
    "        return lst[1] + \" \" + lst[0]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "\n",
    "def get_first_names(author_list):\n",
    "\n",
    "    if len(author_list) > 0:\n",
    "        names = []\n",
    "        for x in author_list:\n",
    "            words_in_name = len(x.split())\n",
    "\n",
    "            if words_in_name > 0:\n",
    "                first = re.sub(r\"[^\\w\\s]\", \"\", x.split()[0])\n",
    "            if words_in_name > 1:\n",
    "                second = re.sub(r\"[^\\w\\s]\", \"\", x.split()[1])\n",
    "            if words_in_name > 2:\n",
    "                third = re.sub(r\"[^\\w\\s]\", \"\", x.split()[2])\n",
    "            if words_in_name > 3:\n",
    "                fourth = re.sub(r\"[^\\w\\s]\", \"\", x.split()[3])\n",
    "\n",
    "            if words_in_name > 0 and len(first) > 1:\n",
    "                names.append(first)\n",
    "            elif words_in_name > 1 and len(second) > 1:\n",
    "                names.append(second)\n",
    "            elif words_in_name > 2 and len(third) > 1:\n",
    "                names.append(third)\n",
    "            elif words_in_name > 3 and len(fourth) > 1:\n",
    "                names.append(fourth)\n",
    "            else:\n",
    "                names.append(x)\n",
    "\n",
    "        return names\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def name_to_gender(first_name_list):\n",
    "    try: \n",
    "        if first_name_list and len(first_name_list) > 0:\n",
    "            return [dict_genders[name] for name in first_name_list]\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_edges(auth_list):\n",
    "    return list(combinations(auth_list, 2))\n",
    "\n",
    "\n",
    "def extract_subject(dc):\n",
    "    try:\n",
    "        result = []\n",
    "        for item in dc:\n",
    "            if type(item) == collections.OrderedDict:\n",
    "                result.append(unidecode(item.get(\"#text\").title().strip()))\n",
    "            elif type(item) == str:\n",
    "                result.append(unidecode(item.title().strip()))\n",
    "            else:\n",
    "                result.append(unidecode(item.title().strip()))\n",
    "        return result\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 57/57 [08:42<00:00,  9.16s/it]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "for year in tqdm(range(1965, 2022)):\n",
    "    file_name = \"data/eric\" + str(year)\n",
    "    with open(file_name + \".xml\", encoding=\"utf-8\") as fd:\n",
    "        dict = xmltodict.parse(fd.read())\n",
    "    recs = [rec[\"metadata\"] for rec in dict[\"records\"][\"record\"]]\n",
    "    df_mini = pd.DataFrame(recs)\n",
    "    \n",
    "    df_mini = df_mini[df_mini[\"dc:type\"].notna()]\n",
    "    df_mini[\"type\"] = [\"\".join(map(str, l)).lower() for l in df_mini[\"dc:type\"]]\n",
    "    df_mini[\"eric:dateAdded\"] = pd.to_numeric(df_mini[\"eric:dateAdded\"])\n",
    "    df.append(df_mini)\n",
    "\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to peer-reviewed journals + all books\n",
    "df = df.loc[\n",
    "    (\n",
    "        (df[\"eric:peer_reviewed\"] == \"T\")\n",
    "        & (df[\"type\"].str.contains(pat=\"journal\", case=False))\n",
    "    )\n",
    "    | (df[\"type\"].str.contains(pat=\"book\", case=False))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 987310/987310 [02:59<00:00, 5495.61it/s]\n",
      "100%|█████████████████████████████████| 980226/980226 [03:43<00:00, 4384.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12279              [Rudolph Masciantonio]\n",
       "17594    [Donivan Watley, Rosalyn Kaplan]\n",
       "17595                     [Lenore Harmon]\n",
       "17596    [William Kuvlesky, Jane Dameron]\n",
       "17730      [Charles Elton, Harriett Rose]\n",
       "17892                 [Jeffrey Greenhaus]\n",
       "17961      [Samuel Osipow, August Scheid]\n",
       "18508                 [Nathaniel Pallone]\n",
       "18572                        [Nancy Cole]\n",
       "18573                      [Milton Hakel]\n",
       "Name: authors, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get author names\n",
    "df[\"authors\"] = df.progress_apply(\n",
    "    lambda row: extract_authors(row[\"dc:creator\"]), axis=1\n",
    ")\n",
    "\n",
    "# remove rows with no human authors\n",
    "df = df[df[\"authors\"].notna()]\n",
    "\n",
    "# clean author name\n",
    "df[\"authors\"] = df.progress_apply(\n",
    "    lambda row: [clean_name(item) for item in row[\"authors\"]], axis=1\n",
    ")\n",
    "df[\"authors\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 980226/980226 [05:36<00:00, 2916.40it/s]\n",
      "100%|█████████████████████████████████| 980226/980226 [03:00<00:00, 5420.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_authors</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>2</td>\n",
       "      <td>[(Donivan Watley, Rosalyn Kaplan)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>2</td>\n",
       "      <td>[(Jane Dameron, William Kuvlesky)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>2</td>\n",
       "      <td>[(Charles Elton, Harriett Rose)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17961</th>\n",
       "      <td>2</td>\n",
       "      <td>[(August Scheid, Samuel Osipow)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_authors                               edges\n",
       "12279          1                                  []\n",
       "17594          2  [(Donivan Watley, Rosalyn Kaplan)]\n",
       "17595          1                                  []\n",
       "17596          2  [(Jane Dameron, William Kuvlesky)]\n",
       "17730          2    [(Charles Elton, Harriett Rose)]\n",
       "17892          1                                  []\n",
       "17961          2    [(August Scheid, Samuel Osipow)]\n",
       "18508          1                                  []\n",
       "18572          1                                  []\n",
       "18573          1                                  []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get edges\n",
    "df[\"n_authors\"] = df.progress_apply(lambda row: len(row[\"authors\"]), axis=1)\n",
    "df[\"edges\"] = df.progress_apply(lambda row: get_edges(sorted(row[\"authors\"])), axis=1)\n",
    "df[[\"n_authors\", \"edges\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 980222/980222 [03:00<00:00, 5439.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc:subject</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>[Audiolingual Methods, Classical Languages, Cu...</td>\n",
       "      <td>[Audiolingual Methods, Classical Languages, Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>[Academic Aspiration, {'@weight': 'MAJOR', '#t...</td>\n",
       "      <td>[Academic Aspiration, Aspiration, Females, Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>[{'@weight': 'MAJOR', '#text': 'Adolescents'},...</td>\n",
       "      <td>[Adolescents, Aspiration, Career Choice, Child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>[{'@weight': 'MAJOR', '#text': 'Aspiration'}, ...</td>\n",
       "      <td>[Aspiration, Black Attitudes, Black Youth, Mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>[{'@weight': 'MAJOR', '#text': 'Ability'}, {'@...</td>\n",
       "      <td>[Ability, Career Choice, Career Development, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892</th>\n",
       "      <td>[Aspiration, {'@weight': 'MAJOR', '#text': 'Ca...</td>\n",
       "      <td>[Aspiration, Career Choice, Career Planning, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17961</th>\n",
       "      <td>[{'@weight': 'MAJOR', '#text': 'Behavior Chang...</td>\n",
       "      <td>[Behavior Change, Behavior Patterns, College S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>[Employment Potential, {'@weight': 'MAJOR', '#...</td>\n",
       "      <td>[Employment Potential, Job Satisfaction, Liter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>[Career Counseling, {'@weight': 'MAJOR', '#tex...</td>\n",
       "      <td>[Career Counseling, Career Guidance, College F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>[College Students, {'@weight': 'MAJOR', '#text...</td>\n",
       "      <td>[College Students, Forced Choice Technique, In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dc:subject  \\\n",
       "12279  [Audiolingual Methods, Classical Languages, Cu...   \n",
       "17594  [Academic Aspiration, {'@weight': 'MAJOR', '#t...   \n",
       "17595  [{'@weight': 'MAJOR', '#text': 'Adolescents'},...   \n",
       "17596  [{'@weight': 'MAJOR', '#text': 'Aspiration'}, ...   \n",
       "17730  [{'@weight': 'MAJOR', '#text': 'Ability'}, {'@...   \n",
       "17892  [Aspiration, {'@weight': 'MAJOR', '#text': 'Ca...   \n",
       "17961  [{'@weight': 'MAJOR', '#text': 'Behavior Chang...   \n",
       "18508  [Employment Potential, {'@weight': 'MAJOR', '#...   \n",
       "18572  [Career Counseling, {'@weight': 'MAJOR', '#tex...   \n",
       "18573  [College Students, {'@weight': 'MAJOR', '#text...   \n",
       "\n",
       "                                                subjects  \n",
       "12279  [Audiolingual Methods, Classical Languages, Cu...  \n",
       "17594  [Academic Aspiration, Aspiration, Females, Mar...  \n",
       "17595  [Adolescents, Aspiration, Career Choice, Child...  \n",
       "17596  [Aspiration, Black Attitudes, Black Youth, Mil...  \n",
       "17730  [Ability, Career Choice, Career Development, C...  \n",
       "17892  [Aspiration, Career Choice, Career Planning, C...  \n",
       "17961  [Behavior Change, Behavior Patterns, College S...  \n",
       "18508  [Employment Potential, Job Satisfaction, Liter...  \n",
       "18572  [Career Counseling, Career Guidance, College F...  \n",
       "18573  [College Students, Forced Choice Technique, In...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get subjects\n",
    "df = df[df[\"dc:subject\"].notna()]\n",
    "df[\"subjects\"] = df.progress_apply(lambda row: extract_subject(row[\"dc:subject\"]), axis=1)\n",
    "df[[\"dc:subject\", \"subjects\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 980222/980222 [03:51<00:00, 4228.04it/s]\n",
      "100%|█████████████████████████████████| 980222/980222 [05:55<00:00, 2758.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_first_names</th>\n",
       "      <th>author_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>[Rudolph]</td>\n",
       "      <td>[male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>[Donivan, Rosalyn]</td>\n",
       "      <td>[male, female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>[Lenore]</td>\n",
       "      <td>[female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>[William, Jane]</td>\n",
       "      <td>[male, female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>[Charles, Harriett]</td>\n",
       "      <td>[male, female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892</th>\n",
       "      <td>[Jeffrey]</td>\n",
       "      <td>[male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17961</th>\n",
       "      <td>[Samuel, August]</td>\n",
       "      <td>[male, male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>[Nathaniel]</td>\n",
       "      <td>[male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>[Nancy]</td>\n",
       "      <td>[female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>[Milton]</td>\n",
       "      <td>[male]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author_first_names  author_genders\n",
       "12279            [Rudolph]          [male]\n",
       "17594   [Donivan, Rosalyn]  [male, female]\n",
       "17595             [Lenore]        [female]\n",
       "17596      [William, Jane]  [male, female]\n",
       "17730  [Charles, Harriett]  [male, female]\n",
       "17892            [Jeffrey]          [male]\n",
       "17961     [Samuel, August]    [male, male]\n",
       "18508          [Nathaniel]          [male]\n",
       "18572              [Nancy]        [female]\n",
       "18573             [Milton]          [male]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load genders from first names\n",
    "df_genders = pd.read_csv(\"df_genders.csv\")[['name', 'gender']]\n",
    "dict_genders = {i[0]:i[1] for i in list(df_genders.values)}\n",
    "\n",
    "# get author first name and then use it to predict gender\n",
    "df[\"author_first_names\"] = df.progress_apply(\n",
    "    lambda row: get_first_names(row[\"authors\"]), axis=1\n",
    ")\n",
    "\n",
    "df[\"author_genders\"] = df.progress_apply(\n",
    "    lambda row: name_to_gender(row[\"author_first_names\"]), axis=1\n",
    ")\n",
    "df[[\"author_first_names\", \"author_genders\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971       29\n",
       "1972       43\n",
       "1973       41\n",
       "1974      386\n",
       "1975     1375\n",
       "1976     1296\n",
       "1977      959\n",
       "1978      856\n",
       "1979     8564\n",
       "1980    15317\n",
       "1981    15367\n",
       "1982    12699\n",
       "1983    13806\n",
       "1984    13964\n",
       "1985    13629\n",
       "1986    13589\n",
       "1987    13703\n",
       "1988    12983\n",
       "1989    15242\n",
       "1990    14651\n",
       "1991    14810\n",
       "1992    15235\n",
       "1993    15201\n",
       "1994    18089\n",
       "1995    17971\n",
       "1996    17603\n",
       "1997    17300\n",
       "1998    15935\n",
       "1999    18417\n",
       "2000    18990\n",
       "2001    17051\n",
       "2002    19610\n",
       "2003    18545\n",
       "2004     7053\n",
       "2005    19040\n",
       "2006    19453\n",
       "2007    28843\n",
       "2008    35349\n",
       "2009    41340\n",
       "2010    37589\n",
       "2011    37225\n",
       "2012    36459\n",
       "2013    19884\n",
       "2014    37284\n",
       "2015    36753\n",
       "2016    39032\n",
       "2017    38620\n",
       "2018    36063\n",
       "2019    37674\n",
       "2020    40255\n",
       "2021    39050\n",
       "Name: eric:dateAdded, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# year-wise counts\n",
    "df[\"eric:dateAdded\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-2223]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"dc:identifier\"].iloc[-2423])\n",
    "print(df[\"dc:creator\"].iloc[-2423])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(df_local):\n",
    "\n",
    "    node_list1 = df_local[\"authors\"].tolist()\n",
    "    node_list2 = [x for x in node_list1 if x is not None]  # remove none\n",
    "    node_list3 = [item for sublist in node_list2 for item in sublist]\n",
    "    node_list = list(set(node_list3))\n",
    "\n",
    "    n_papers_per_author = len(node_list3) / len(node_list)\n",
    "\n",
    "    edge_list1 = df_local[\"edges\"].tolist()\n",
    "    edge_list2 = [x for x in edge_list1 if x is not None]  # remove none\n",
    "    edge_list = [item for sublist in edge_list2 for item in sublist]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_list)\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    return (G, n_papers_per_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████▍              | 34/57 [3:36:08<14:02:19, 2197.35s/it]"
     ]
    }
   ],
   "source": [
    "# CUMULATIVE NOW\n",
    "graph_list = []\n",
    "\n",
    "for year in tqdm(range(1965, 2022)):\n",
    "\n",
    "    df_local = df.loc[df[\"eric:dateAdded\"] <= year]\n",
    "\n",
    "    if len(df_local) == 0:\n",
    "        continue\n",
    "\n",
    "    result = generate_graph(df_local)\n",
    "    G = result[0]\n",
    "    \n",
    "    n_authors = len(G)\n",
    "    n_papers = len(df_local)\n",
    "    n_authors_per_paper = df_local[\"n_authors\"].mean()\n",
    "    n_papers_per_author = result[1]\n",
    "    n_collabs = nx.number_of_edges(G)\n",
    "    n_isolates = nx.number_of_isolates(G)\n",
    "    mean_collabs = 2 * G.number_of_edges() / float(G.number_of_nodes())\n",
    "\n",
    "    G_largest_comp = G.subgraph(\n",
    "        sorted(nx.connected_components(G), key=len, reverse=True)[0]\n",
    "    )\n",
    "    largest_component = len(G_largest_comp) / len(G)\n",
    "    \n",
    "    G_largest_bicomp = G.subgraph(\n",
    "        sorted(nx.biconnected_components(G), key=len, reverse=True)[0]\n",
    "    )\n",
    "    largest_bicomponent = len(G_largest_bicomp) / len(G)\n",
    "\n",
    "    deg_assort = nx.degree_assortativity_coefficient(G)\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    transitivity = nx.transitivity(G)\n",
    "    \n",
    "    avg_path_len = nx.average_shortest_path_length(G_largest_comp)\n",
    "    \n",
    "\n",
    "    graph_list.append(\n",
    "        (\n",
    "            year,\n",
    "            n_authors,\n",
    "            n_papers,\n",
    "            n_authors_per_paper,\n",
    "            n_papers_per_author,\n",
    "            n_collabs,\n",
    "            n_isolates,\n",
    "            mean_collabs,\n",
    "            largest_component,\n",
    "            largest_bicomponent,\n",
    "            deg_assort,\n",
    "            avg_clustering,\n",
    "            transitivity,\n",
    "            avg_path_len\n",
    "        )\n",
    "    )\n",
    "\n",
    "df_summary = pd.DataFrame(\n",
    "    graph_list,\n",
    "    columns=[\n",
    "        \"year\",\n",
    "        \"n_authors\",\n",
    "        \"n_papers\",\n",
    "        \"n_authors_per_paper\",\n",
    "        \"n_papers_per_author\",\n",
    "        \"n_collabs\",\n",
    "        \"n_isolates\",\n",
    "        \"mean_collabs\",\n",
    "        \"largest_component\",\n",
    "        \"largest_bicomponent\",\n",
    "        \"deg_assort\",\n",
    "        \"avg_clustering\",\n",
    "        \"transitivity\",\n",
    "        \"avg_path_len\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv(\"df_graph_summary.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Facet 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"n_authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"n_papers\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Facet 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"n_authors_per_paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"n_papers_per_author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"n_collabs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"mean_collabs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=Tru\n",
    ").encode(x=\"year\", y=\"n_isolates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"largest_component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"deg_assort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"avg_clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_summary).mark_area(\n",
    "    color=\"lightblue\", line=True\n",
    ").encode(x=\"year\", y=\"transitivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "\n",
    "result = generate_graph(df)\n",
    "G = result[0]\n",
    "n_authors = len(G)\n",
    "n_papers = len(df)\n",
    "\n",
    "n_authors_per_paper = df[\"n_authors\"].mean()\n",
    "n_papers_per_author = result[1]\n",
    "\n",
    "n_collabs = nx.number_of_edges(G)\n",
    "n_isolates = nx.number_of_isolates(G)\n",
    "mean_collabs = 2 * G.number_of_edges() / float(G.number_of_nodes())\n",
    "\n",
    "G_largest_comp = G.subgraph(\n",
    "    sorted(nx.connected_components(G), key=len, reverse=True)[0]\n",
    ")\n",
    "largest_component = len(G_largest_comp) / len(G)\n",
    "\n",
    "G_largest_bicomp = G.subgraph(\n",
    "    sorted(nx.biconnected_components(G), key=len, reverse=True)[0]\n",
    ")\n",
    "largest_bicomponent = len(G_largest_bicomp) / len(G)\n",
    "\n",
    "deg_assort = nx.degree_assortativity_coefficient(G)\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "transitivity = nx.transitivity(G)\n",
    "\n",
    "avg_path_len = nx.average_shortest_path_length(G_largest_comp)\n",
    "\n",
    "list1.append(\n",
    "    (\n",
    "        year,\n",
    "        n_authors,\n",
    "        n_papers,\n",
    "        n_authors_per_paper,\n",
    "        n_papers_per_author,\n",
    "        n_collabs,\n",
    "        n_isolates,\n",
    "        mean_collabs,\n",
    "        largest_component,\n",
    "        largest_bicomponent,\n",
    "        deg_assort,\n",
    "        avg_clustering,\n",
    "        transitivity,\n",
    "        avg_path_len\n",
    "    )\n",
    ")\n",
    "\n",
    "df_overall = pd.DataFrame(\n",
    "    list1,\n",
    "    columns=[\n",
    "        \"year\",\n",
    "        \"n_authors\",\n",
    "        \"n_papers\",\n",
    "        \"n_authors_per_paper\",\n",
    "        \"n_papers_per_author\",\n",
    "        \"n_collabs\",\n",
    "        \"n_isolates\",\n",
    "        \"mean_collabs\",\n",
    "        \"largest_component\",\n",
    "        \"largest_bicomponent\",\n",
    "        \"deg_assort\",\n",
    "        \"avg_clustering\",\n",
    "        \"transitivity\",\n",
    "        \"avg_path_len\"\n",
    "    ],\n",
    ")\n",
    "df_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most influential researchers\n",
    "ec_dict = nx.eigenvector_centrality(G)\n",
    "sorted(ec_dict.items(), key=lambda item: item[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 1: Changing likelihood of co-authorships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collaboration'] = np.where(df['n_authors'] > 1, 1, 0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fig = df.groupby('eric:dateAdded')[['collaboration']].mean().reset_index()\n",
    "\n",
    "alt.Chart(df_fig).mark_line().encode(x=\"eric:dateAdded\", y=\"collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_largest_bicomp = G.subgraph(\n",
    "    sorted(nx.biconnected_components(G), key=len, reverse=True)[0]\n",
    ")\n",
    "largest_bicomponent = len(G_largest_bicomp) / len(G)\n",
    "largest_bicomponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted((d for n, d in G.degree()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim([10, 1000])\n",
    "ax.scatter(*np.unique(degree_sequence, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if power law holds\n",
    "import powerlaw\n",
    "results = powerlaw.Fit(degree_sequence)\n",
    "print(results.power_law.alpha)\n",
    "print(results.power_law.xmin)\n",
    "results.distribution_compare('power_law', 'exponential', normalized_ratio = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_random = nx.gnm_random_graph(749249, 1704772, seed=27, directed=False)\n",
    "nx.info(G_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_shortest_path_length(G_largest_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_random_largest_comp = G_random.subgraph(\n",
    "    sorted(nx.connected_components(G_random), key=len, reverse=True)[0]\n",
    ")\n",
    "nx.average_shortest_path_length(G_random_largest_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 5: Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list1 = df[\"subjects\"].to_list()\n",
    "node_list2 = [x for x in node_list1 if x is not None]  # remove none\n",
    "node_list3 = [item for sublist in node_list2 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take subjects out for manual coding quant 0/1\n",
    "df_temp = pd.DataFrame(Counter(node_list3).most_common(), columns=[\"subject\", \"n\"])\n",
    "df_temp.to_csv(\"subjects.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
